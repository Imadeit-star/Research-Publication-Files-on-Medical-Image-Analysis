{"cells":[{"cell_type":"code","execution_count":null,"id":"11bf6f19-81e6-4fa4-baf1-63135ea5c97d","metadata":{"scrolled":true,"id":"11bf6f19-81e6-4fa4-baf1-63135ea5c97d","outputId":"45004d2d-3f44-4bc5-b29f-bd8b0d5d4119"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","2025-10-09 07:15:28.794863: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-10-09 07:15:28.873179: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","/usr/local/lib/python3.8/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n"]}],"source":["# Loading Dependencies for Medical Image Analysis\n","import optuna\n","from tensorflow.keras.applications import ResNet101\n","from tensorflow.keras.models import Model\n","import matplotlib.pyplot as plt # Import matplotlib.pyplot\n","import torch.nn as nn\n","from torchsummary import summary\n","import torchvision.models as models\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","import seaborn as sns\n","import torchvision\n","import torch.optim as optim  # Import the optim module\n","import numpy as np\n","import torchvision.transforms as transforms\n","#from torch.utils.data import DataLoader, Subset\n","#from torchvision.datasets import ImageFolder\n","#from torchvision import datasets\n","import torchvision.datasets as datasets\n","from torch.utils.data import Dataset, DataLoader, Subset\n","#from torchvision import transforms\n","import os\n","import torch\n","from PIL import Image\n","#import matplotlib.pyplot as plt\n","#import time\n","import copy\n","#import os\n","import IPython\n","import time\n","from sklearn.model_selection import KFold\n","import threading\n","import optuna.visualization\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from skopt import gp_minimize\n","from skopt.space import Real, Categorical, Integer\n","from skopt.utils import use_named_args\n","import GPyOpt\n","import GPy\n","from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n","from torch.optim.lr_scheduler import (\n","    StepLR,\n","    ReduceLROnPlateau,\n","    CosineAnnealingLR,\n","    CyclicLR,\n","    OneCycleLR,\n",")"]},{"cell_type":"code","execution_count":null,"id":"217aab95-eeb7-44b9-939b-a41cd0d97a32","metadata":{"id":"217aab95-eeb7-44b9-939b-a41cd0d97a32"},"outputs":[],"source":["def create_scheduler(optimizer, scheduler_type, **kwargs): # This function defines the scheduler types\n","    if scheduler_type == \"StepLR\":\n","        return StepLR(optimizer, **kwargs)\n","    elif scheduler_type == \"ReduceLROnPlateau\":\n","        return ReduceLROnPlateau(optimizer, **kwargs)\n","    elif scheduler_type == \"CosineAnnealingLR\":\n","        return CosineAnnealingLR(optimizer, **kwargs)\n","    elif scheduler_type == \"CyclicLR\":\n","        return CyclicLR(optimizer, cycle_momentum=False, **kwargs)\n","    elif scheduler_type == \"OneCycleLR\":\n","        return OneCycleLR(optimizer, **kwargs)\n","    else:\n","        raise ValueError(f\"Unknown scheduler type: {scheduler_type}\")"]},{"cell_type":"code","execution_count":null,"id":"fc8561f1-9c61-4171-9413-29a320b0fa99","metadata":{"id":"fc8561f1-9c61-4171-9413-29a320b0fa99"},"outputs":[],"source":["#scheduler_types = [\"StepLR\", \"ReduceLROnPlateau\", \"CosineAnnealingLR\", \"CyclicLR\", \"OneCycleLR\"]\n","scheduler_types = \"OneCycleLR\" # Specify the scheduler here"]},{"cell_type":"code","execution_count":null,"id":"57541d37-ba51-44ac-a5f2-444430e0f7b9","metadata":{"id":"57541d37-ba51-44ac-a5f2-444430e0f7b9"},"outputs":[],"source":["K = 10  # Example K value\n","best_params_for_k = {\n","    \"learning_rate\":0.0001823817366005471, # Example learning rate for K=5\n","    \"dropout_rate\":0.21623344843587963,     # Example dropout rate for K=5\n","    \"batch_size\":16, # Example batch size for K=5\n","    \"num_epochs\":86 # Example number of epochs for K=5\n","}\n","#scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0.0005537021899767878)  # Initialize scheduler\n"]},{"cell_type":"code","execution_count":null,"id":"609afcd8-8fff-48cf-b697-9c4d90b07354","metadata":{"id":"609afcd8-8fff-48cf-b697-9c4d90b07354"},"outputs":[],"source":["\n","def Model_ResNet101_PyTorch(learning_rate, dropout_rate):\n","    # Load pre-trained ResNet101\n","    model = models.resnet101(weights='ResNet101_Weights.DEFAULT')\n","\n","    # Modify the input layer to accept 3 channels (assuming your input is RGB)\n","    # model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","\n","    # Freeze all layers initially\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    # Unfreeze the desired layers for fine-tuning\n","    for param in model.layer3.parameters(): # Unfreeze Layer 3\n","        param.requires_grad = True\n","\n","    for param in model.layer4.parameters(): # Unfreeze Layer 4\n","        param.requires_grad = True\n","\n","    for param in model.fc.parameters(): # Unfreeze the fully connected layer\n","        param.requires_grad = True\n","\n","    # Modification of the classifier layer (fully connected layer)\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Sequential(\n","        nn.Linear(num_ftrs, 3),        # 3 output classes (adjust if you have a different number of classes)\n","        nn.Dropout(dropout_rate),\n","        nn.Softmax(dim=1)              # Softmax activation for multi-class classification\n","    )\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    summary(model, (3, 224, 224), device = str(device))  # Print model summary (adjust input size if needed)\n","\n","    # Define loss function and optimizer\n","    criterion = nn.CrossEntropyLoss() # Appropriate for multi-class classification\n","\n","    # Define optimizer - consider using a lower learning rate for earlier unfrozen layers if needed\n","    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=0.01)\n","\n","\n","    return model, criterion, optimizer"]},{"cell_type":"code","execution_count":null,"id":"556853b9-ccce-44b9-8b8f-69ce2bf64d15","metadata":{"id":"556853b9-ccce-44b9-8b8f-69ce2bf64d15","outputId":"650a8fae-4bfb-44bd-e884-5ae97d1b6c16"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n"]}],"source":["model, criterion, optimizer = Model_ResNet101_PyTorch(learning_rate=best_params_for_k[\"learning_rate\"],\n","                                                      dropout_rate= best_params_for_k[\"dropout_rate\"])"]},{"cell_type":"code","execution_count":null,"id":"43880228-5bd0-4849-943b-930c3a66c90a","metadata":{"id":"43880228-5bd0-4849-943b-930c3a66c90a"},"outputs":[],"source":["# We pass the scheduler types to the training loop at this portion\n","#scheduler = ReduceLROnPlateau(optimizer, mode='min', factor =0.13700840866435451, patience = 10)\n","#scheduler = StepLR(optimizer, step_size = 7, gamma=0.6529691827085107)\n","#scheduler = CosineAnnealingLR(optimizer, T_max=6, eta_min=9.777678382795824e-05) # Initialize scheduler\n","#scheduler = OneCycleLR(optimizer, max_lr=0.005433329251927817, epochs=86, steps_per_epoch=19)\n","scheduler = CyclicLR(optimizer, base_lr = 2.5696458587770245e-06, max_lr = 0.000577228568316326, step_size_up =8.0,\n","                    step_size_down = 9.0, mode = \"triangular\")"]},{"cell_type":"code","execution_count":null,"id":"cf862b26-38fe-47b5-95c6-f57a26080c60","metadata":{"id":"cf862b26-38fe-47b5-95c6-f57a26080c60"},"outputs":[],"source":["class MedicalImageDataset(Dataset):\n","       def __init__(self, root_dir, image_extensions, transform=None):\n","           self.root_dir = root_dir\n","           self.image_extensions = image_extensions\n","           #self.transform = transform\n","           self.image_paths = []\n","           self.labels = []\n","\n","           for class_name in os.listdir(root_dir):\n","               class_path = os.path.join(root_dir, class_name)\n","               if os.path.isdir(class_path):\n","                   for filename in os.listdir(class_path):\n","                       if filename.lower().endswith(image_extensions):\n","                           self.image_paths.append(os.path.join(class_path, filename))\n","                           self.labels.append(class_name)  # Assuming subfolder name is the label\n","\n","       def __len__(self):\n","           return len(self.image_paths)\n","\n","       def __getitem__(self, idx):\n","           image_path = self.image_paths[idx]\n","           image = np.array(Image.open(image_path).convert('RGB'))  # Convert to NumPy array\n","           label = self.labels[idx]\n","           label_mapping = {'Benign': 0, 'Malignant': 1, 'Normal': 2}\n","           label = label_mapping.get(label)  # Apply the label mapping here\n","           #image = np.array(image)\n","\n","           return image, label"]},{"cell_type":"code","execution_count":null,"id":"f5178825-6d84-49e1-b4d6-686047c5e9a8","metadata":{"id":"f5178825-6d84-49e1-b4d6-686047c5e9a8"},"outputs":[],"source":["dataset_path = '/home/workspace/PetersWorkspace/Abbans/TMPFS_Medical_Images/Medical_Images/'\n","#dataset_path = '/usr/bin/Medical_Images'\n","image_extensions = ('.png','.jpg')\n","\n","dataset = MedicalImageDataset(dataset_path, image_extensions)"]},{"cell_type":"code","execution_count":null,"id":"c631c936-8ca4-40da-9a58-e0387f91a823","metadata":{"id":"c631c936-8ca4-40da-9a58-e0387f91a823"},"outputs":[],"source":["# Splitting the dataset based on their split proportions\n","Train_ratio = 0.70 # Ration of Training Data\n","Validaton_ratio = 0.15  # Ratio of Testing Data\n","Testing_ratio = 0.15 # Ration of Testing Data\n","\n","torch.manual_seed(42)  # You can choose any integer as your seed\n","# Calculate the sizes of the train, validation, and test sets\n","Dataset_size = len(dataset) # Determines the dataset size\n","#Train_size = int(Train_ratio * Dataset_size) # Determines the train dataset size\n","#Validation_size = int(Validaton_ratio * Dataset_size) # Determines the validation dataset size\n","Test_size = int(Testing_ratio * Dataset_size) # Determines the test dataset size\n","#Test_size = Dataset_size - Train_size - Validation_size # Determines the test dataset size\n","Dataset_Train_Valid = Dataset_size - Test_size # Determines the new dataset size\n","\n","# Split the dataset into train, validation, and test sets\n"," #Train_dataset, Validation_dataset, Test_dataset = torch.utils.data.random_split(dataset, [Train_size, Validation_size, Test_size])\n","Dataset_New, Test_dataset = torch.utils.data.random_split(dataset, [Dataset_Train_Valid, Test_size])"]},{"cell_type":"code","execution_count":null,"id":"23ffbbad-b98c-4ea9-9f7b-63dedfcb4844","metadata":{"id":"23ffbbad-b98c-4ea9-9f7b-63dedfcb4844","outputId":"9a6bf9e1-ccb2-4ca7-b82b-a117b88d462f"},"outputs":[{"name":"stdout","output_type":"stream","text":["661\n","116\n"]}],"source":["#print(len(Train_dataset))\n","#print(len(Validation_dataset))\n","#print(len(Test_dataset))\n","print(len(Dataset_New))\n","print(len(Test_dataset))"]},{"cell_type":"code","execution_count":null,"id":"4c79b141-59ec-4d60-b7e1-24c4160b292e","metadata":{"id":"4c79b141-59ec-4d60-b7e1-24c4160b292e"},"outputs":[],"source":["# Defining Augmentation for my Training Dataset\n","#For the training dataset\n","#For the training dataset\n","Fundamental_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.4),\n","    transforms.RandomVerticalFlip(p=0.2),\n","    transforms.RandomRotation(degrees=(-10, 10)),\n","    transforms.RandomAffine(degrees=0, translate=(0.08, 0.08), scale=(0.92, 1.08)),\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n","    transforms.RandomResizedCrop(size=(224, 224), scale=(0.85, 1.0)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"cell_type":"code","execution_count":null,"id":"03084e64-108f-4dc3-9002-369f6e637788","metadata":{"id":"03084e64-108f-4dc3-9002-369f6e637788"},"outputs":[],"source":["Advanced_transform = A.Compose([\n","    A.MedianBlur(blur_limit=3, p=1),\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","    A.Rotate(limit=5, p=0.5),\n","    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.08, rotate_limit=12, p=0.5),\n","    A.RandomSizedCrop(min_max_height=(160, 224), size =(224, 224), p=0.5),\n","    A.ElasticTransform(alpha=0.8, sigma=40, alpha_affine=40, p = 0.5),\n","    A.GridDistortion(p=0.4, distort_limit=0.4),\n","    A.OpticalDistortion(p=0.05, distort_limit=0.05, shift_limit=0.5),\n","    #A.GaussianBlur(blur_limit=(3, 7), p=0.5),  # Gaussian Blur applied after spatial transformations\n","    # CoarseDropout(Random Erasing)\n","    A.CoarseDropout(max_holes=1, max_height=32, max_width=32, min_holes=1, min_height=16,\n","                    min_width=16, fill_value=0,\n","        p=0.5,),\n","\n","    # Pixel-Level Transformations\n","    A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=0.3),\n","    #A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=20, p=0.4),\n","    A.CLAHE(clip_limit=3.0, tile_grid_size=(6, 6), p=0.25),  # Contrast Limited Adaptive Histogram Equalization\n","\n","    # Noise Injection\n","    #A.GaussNoise(var_limit=(0.01, 0.05), p=0.5),\n","    #A.MultiplicativeNoise(multiplier=(0.9, 1.1), elementwise=True, p=0.3),  # Speckle noise\n","\n","         # Blurring and Sharpening\n","    #A.OneOf([A.MedianBlur(blur_limit=3, p=0.5),],p=0.1),\n","\n","    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),\n","\n","    # Normalization\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2(),\n","])"]},{"cell_type":"code","execution_count":null,"id":"e104d4a4-dcc1-4fe6-ab85-211462a7de2c","metadata":{"id":"e104d4a4-dcc1-4fe6-ab85-211462a7de2c"},"outputs":[],"source":["Train_transform = transforms.Compose([\n","    transforms.ToPILImage(), # Conversion of Images into PIL for Albumentation\n","    Advanced_transform, # Application of advanced transformations\n","    Fundamental_transform, # Application of fundamental transformation\n","])"]},{"cell_type":"code","execution_count":null,"id":"0983184b-a956-4c1d-a6be-fe789d435a64","metadata":{"id":"0983184b-a956-4c1d-a6be-fe789d435a64"},"outputs":[],"source":["# Defining Augmentation for my Validaton Dataset\n","Validation_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"cell_type":"code","execution_count":null,"id":"ffab9949-1a5d-460b-a973-a5ab6171ee89","metadata":{"id":"ffab9949-1a5d-460b-a973-a5ab6171ee89"},"outputs":[],"source":["# Defining Augmentation for the Testing Dataset\n","Test_transform = transforms.Compose([\n","    # Only resize and normalize for test set\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"cell_type":"code","execution_count":null,"id":"08c23005-9898-4c3a-9c37-3e67be910aa9","metadata":{"id":"08c23005-9898-4c3a-9c37-3e67be910aa9"},"outputs":[],"source":["# Applying the Augmentation to the Test dataset\n","Test_dataset.dataset.transform = Test_transform"]},{"cell_type":"code","execution_count":null,"id":"661e537f-5dc3-49bb-8404-a2fc470191eb","metadata":{"id":"661e537f-5dc3-49bb-8404-a2fc470191eb"},"outputs":[],"source":["Dataset_New.dataset.transform = Train_transform"]},{"cell_type":"code","execution_count":null,"id":"0dcf2cb6-fead-422c-a40e-dbf1cc85bb3a","metadata":{"id":"0dcf2cb6-fead-422c-a40e-dbf1cc85bb3a"},"outputs":[],"source":["def my_collate_fn(batch):\n","            images = []\n","            labels = []\n","\n","            for image, label in batch:\n","                image = transforms.ToPILImage()(image)  # Convert to PIL Image\n","                image = transforms.Resize((224, 224))(image)  # Add resize transform here\n","                image = transforms.ToTensor()(image)  # Convert to Tensor using ToTensor\n","                images.append(image)\n","                labels.append(label)\n","\n","            # Stack images into a batch tensor\n","            images = torch.stack(images, dim=0)\n","            labels = torch.tensor(labels)\n","            return images, labels\n"]},{"cell_type":"code","execution_count":null,"id":"5455d246-6fab-40a8-8e47-de7aea9bf2cf","metadata":{"id":"5455d246-6fab-40a8-8e47-de7aea9bf2cf"},"outputs":[],"source":["# Creating my Test dataloader\n","Test_dataloader = DataLoader(Test_dataset, batch_size=best_params_for_k[\"batch_size\"],\n","                             shuffle=False, collate_fn = my_collate_fn, num_workers = 32) # New"]},{"cell_type":"code","execution_count":null,"id":"664b5bd1-befd-48a6-8a9f-a4697a914ae6","metadata":{"id":"664b5bd1-befd-48a6-8a9f-a4697a914ae6"},"outputs":[],"source":["train_loader = DataLoader(Dataset_New, batch_size=best_params_for_k[\"batch_size\"], shuffle=True, num_workers = 32, collate_fn = my_collate_fn)"]},{"cell_type":"code","execution_count":null,"id":"7f46e23c-f4ef-451b-9bc1-61c1f0468148","metadata":{"id":"7f46e23c-f4ef-451b-9bc1-61c1f0468148"},"outputs":[],"source":["# Model to be runned for final evauation process:\n","def Train_Model_Final(model, criterion, optimizer, train_loader, num_epochs, scheduler, scheduler_type):\n","    since = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    train_acc_history = []\n","    train_loss_history = []\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(str(device))\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","\n","        # Training phase only\n","        model.train()\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for inputs, labels in train_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            with torch.set_grad_enabled(True):\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","\n","                loss.backward()\n","                optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n","\n","        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","        train_acc_history.append(epoch_acc)\n","        train_loss_history.append(epoch_loss)\n","\n","        # Update best model weights (optional, based on training accuracy)\n","        if epoch_acc > best_acc:\n","            best_acc = epoch_acc\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        if scheduler_type in [\"CosineAnnealingLR\", \"OneCycleLR\", \"CyclicLR\"]:\n","          scheduler.step()\n","        elif scheduler_type == \"StepLR\":\n","            if (epoch + 1) % scheduler.step_size == 0:\n","                scheduler.step()\n","                # StepLR is typically called after a certain number of epochs (step_size)\n","        elif scheduler_type == \"ReduceLROnPlateau\":\n","            pass # because we are in the training loop and so no validation dataset applied\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print(f'Training is completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best train Acc: {best_acc:4f}')  # Based on training accuracy\n","\n","    model.load_state_dict(best_model_wts)\n","    return model, train_acc_history, train_loss_history"]},{"cell_type":"code","execution_count":null,"id":"6420a3ad-1162-4207-9fa3-f21f3b1f65b5","metadata":{"id":"6420a3ad-1162-4207-9fa3-f21f3b1f65b5"},"outputs":[],"source":["class_names = ['Benign', 'Malignant', 'Normal']"]},{"cell_type":"code","execution_count":null,"id":"7dbc35b6-34fe-4c81-952e-4fd77f901164","metadata":{"id":"7dbc35b6-34fe-4c81-952e-4fd77f901164"},"outputs":[],"source":["# Modified Train_Model_Final_KFold function\n","def Train_Model_Final_KFold(model, criterion, optimizer, Dataset_New, num_epochs, scheduler, scheduler_type, K):\n","\n","    since = time.time()\n","    # best_model_wts = copy.deepcopy(model.state_dict()) # We might not need to save a \"best\" model here in the same way, as each fold trains a model on the full dataset\n","    # best_loss = float('inf') # Not tracking validation loss for early stopping here\n","    train_acc_history = [] # Still useful to see training progress\n","    train_loss_history = [] # Still useful to see training progress\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(str(device))\n","\n","    kf = KFold(n_splits=K, shuffle=True, random_state=42)\n","\n","    # List to store the trained models from each fold\n","    trained_models = []\n","\n","    # We will iterate K times, but use the entire Dataset_New for training each time\n","    # The KFold split is used conceptually here to iterate K times, but the indices are not used to create subsets for training.\n","    for fold in range(K):\n","        print(f\"Training Fold {fold + 1}/{K}\")\n","\n","        # Create a DataLoader for the entire Dataset_New for training\n","        # Ensure the Dataset_New has the training transform applied\n","        Dataset_New.dataset.transform = Train_transform\n","\n","        def my_collate_fn(batch):\n","            images = []\n","            labels = []\n","\n","            for image, label in batch:\n","                image = transforms.ToPILImage()(image)  # Convert to PIL Image\n","                image = transforms.Resize((224, 224))(image)  # Add resize transform here\n","                image = transforms.ToTensor()(image)  # Convert to Tensor using ToTensor\n","                images.append(image)\n","                labels.append(label)\n","\n","            # Stack images into a batch tensor\n","            images = torch.stack(images, dim=0)\n","            labels = torch.tensor(labels)\n","            return images, labels\n","\n","        train_loader = DataLoader(Dataset_New, batch_size=best_params_for_k[\"batch_size\"], shuffle=True, num_workers = 32, collate_fn = my_collate_fn)\n","\n","        # Create a new model instance for each fold to ensure fresh weights\n","        fold_model, fold_criterion, fold_optimizer = Model_ResNet101_PyTorch(learning_rate=best_params_for_k[\"learning_rate\"],\n","                                                                              dropout_rate= best_params_for_k[\"dropout_rate\"])\n","\n","        fold_model.to(str(device))\n","        # Re-initialize the scheduler for each fold's optimizer\n","        # If using Optuna, you would need pass best scheduler type and its params here.\n","        scheduler_fold = create_scheduler(\n","             fold_optimizer, # leave as it is it automatically picks from the scheduler being used\n","             scheduler_type, # Leave as it is, it automatically picks from the scheduler being used\n","           max_lr=0.005433329251927817, epochs=86, steps_per_epoch=19) # specify this value per-scheduler type used manually for each run\n","\n","\n","        # Train the model on the entire Dataset_New\n","        trained_model_fold, fold_train_acc_history, fold_train_loss_history = Train_Model_Final(fold_model, fold_criterion, fold_optimizer,\n","                                                                                                train_loader, num_epochs, scheduler_fold, scheduler_type)\n","\n","        # Store the trained model for later evaluation\n","        trained_models.append(copy.deepcopy(trained_model_fold.state_dict()))\n","\n","    time_elapsed = time.time() - since\n","    print(f'Total training time for {K} folds: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","\n","    # Return the list of trained model state dictionaries\n","    return trained_models"]},{"cell_type":"code","execution_count":null,"id":"78e885ed-2771-4339-aa33-9adb513969ae","metadata":{"id":"78e885ed-2771-4339-aa33-9adb513969ae"},"outputs":[],"source":["# This Gap is left to separate the two Training_Model_Final_KFolds"]},{"cell_type":"code","execution_count":null,"id":"85417322-bef5-491a-8e2c-c9066b908c9c","metadata":{"id":"85417322-bef5-491a-8e2c-c9066b908c9c","outputId":"01c960a1-8ad7-4d65-a723-e89b03b9d2b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Fold 1/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9575 Acc: 0.5870\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7851 Acc: 0.7806\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.7067 Acc: 0.8790\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6822 Acc: 0.8850\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6518 Acc: 0.9289\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6476 Acc: 0.9198\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6428 Acc: 0.9153\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6265 Acc: 0.9365\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6197 Acc: 0.9486\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6264 Acc: 0.9440\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6139 Acc: 0.9440\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6183 Acc: 0.9410\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6162 Acc: 0.9425\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6265 Acc: 0.9334\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6350 Acc: 0.9259\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6181 Acc: 0.9440\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6088 Acc: 0.9455\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6028 Acc: 0.9637\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6137 Acc: 0.9516\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6144 Acc: 0.9501\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.6142 Acc: 0.9455\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6209 Acc: 0.9365\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6125 Acc: 0.9410\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6208 Acc: 0.9440\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6057 Acc: 0.9425\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6031 Acc: 0.9486\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.5978 Acc: 0.9637\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.5910 Acc: 0.9607\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.5940 Acc: 0.9637\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.6025 Acc: 0.9607\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.6032 Acc: 0.9501\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.6011 Acc: 0.9561\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.6159 Acc: 0.9425\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6329 Acc: 0.9304\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.6648 Acc: 0.8986\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.6389 Acc: 0.9228\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.6324 Acc: 0.9304\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6150 Acc: 0.9531\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.6310 Acc: 0.9304\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.6451 Acc: 0.9198\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.6468 Acc: 0.9123\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.6429 Acc: 0.9274\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.6406 Acc: 0.9123\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.6473 Acc: 0.9183\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.6437 Acc: 0.9198\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.6587 Acc: 0.8986\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.6471 Acc: 0.9107\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.6351 Acc: 0.9213\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.6302 Acc: 0.9319\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.6135 Acc: 0.9395\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.6100 Acc: 0.9440\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.6019 Acc: 0.9546\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.6059 Acc: 0.9576\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.5878 Acc: 0.9713\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.5931 Acc: 0.9682\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.5999 Acc: 0.9652\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.5998 Acc: 0.9713\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.5952 Acc: 0.9667\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.5928 Acc: 0.9788\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.5949 Acc: 0.9667\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.5932 Acc: 0.9561\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.6032 Acc: 0.9576\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.6101 Acc: 0.9486\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.6190 Acc: 0.9365\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.6219 Acc: 0.9274\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6380 Acc: 0.9244\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6317 Acc: 0.9259\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.6364 Acc: 0.9244\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.6267 Acc: 0.9395\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.6529 Acc: 0.9047\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.6172 Acc: 0.9486\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6514 Acc: 0.9032\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.6265 Acc: 0.9410\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.6411 Acc: 0.9168\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.6190 Acc: 0.9486\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.6123 Acc: 0.9516\n","\n","Training is completed in 6m 8s\n","Best train Acc: 0.978820\n","Training Fold 2/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9708 Acc: 0.5734\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7859 Acc: 0.7761\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.6867 Acc: 0.8926\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6577 Acc: 0.9153\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6736 Acc: 0.9032\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6423 Acc: 0.9168\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6315 Acc: 0.9349\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6286 Acc: 0.9380\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6277 Acc: 0.9304\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6185 Acc: 0.9455\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6247 Acc: 0.9410\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6208 Acc: 0.9455\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6209 Acc: 0.9425\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6180 Acc: 0.9470\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6222 Acc: 0.9425\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6155 Acc: 0.9425\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6152 Acc: 0.9516\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6155 Acc: 0.9486\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6111 Acc: 0.9531\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6079 Acc: 0.9637\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.6104 Acc: 0.9486\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6087 Acc: 0.9531\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6259 Acc: 0.9470\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6284 Acc: 0.9334\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6176 Acc: 0.9531\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6118 Acc: 0.9425\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.5979 Acc: 0.9592\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.6033 Acc: 0.9561\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.5959 Acc: 0.9713\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.6023 Acc: 0.9637\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.6170 Acc: 0.9440\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.6143 Acc: 0.9486\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.6539 Acc: 0.9092\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6323 Acc: 0.9395\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.6256 Acc: 0.9425\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.6322 Acc: 0.9334\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.6156 Acc: 0.9455\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6089 Acc: 0.9607\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.6132 Acc: 0.9455\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.6148 Acc: 0.9592\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.6132 Acc: 0.9470\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.6282 Acc: 0.9486\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.6014 Acc: 0.9622\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.5916 Acc: 0.9652\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.5954 Acc: 0.9576\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.5901 Acc: 0.9682\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.6225 Acc: 0.9289\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.6328 Acc: 0.9228\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.6219 Acc: 0.9365\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.6198 Acc: 0.9334\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.6228 Acc: 0.9440\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.6358 Acc: 0.9259\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.6293 Acc: 0.9289\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.6132 Acc: 0.9380\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.6411 Acc: 0.9274\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.6122 Acc: 0.9380\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.6227 Acc: 0.9470\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.6086 Acc: 0.9410\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.6061 Acc: 0.9561\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.5949 Acc: 0.9637\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.6031 Acc: 0.9531\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.5996 Acc: 0.9622\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.6012 Acc: 0.9576\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.6122 Acc: 0.9486\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.6081 Acc: 0.9561\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6054 Acc: 0.9531\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6083 Acc: 0.9516\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.6336 Acc: 0.9228\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.6320 Acc: 0.9259\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.6265 Acc: 0.9304\n","\n","Epoch 70/85\n","----------\n","Train Loss: 0.6157 Acc: 0.9425\n","\n","Epoch 71/85\n","----------\n","Train Loss: 0.6376 Acc: 0.9274\n","\n","Epoch 72/85\n","----------\n","Train Loss: 0.6137 Acc: 0.9455\n","\n","Epoch 73/85\n","----------\n","Train Loss: 0.6237 Acc: 0.9380\n","\n","Epoch 74/85\n","----------\n","Train Loss: 0.6282 Acc: 0.9365\n","\n","Epoch 75/85\n","----------\n","Train Loss: 0.6091 Acc: 0.9546\n","\n","Epoch 76/85\n","----------\n","Train Loss: 0.6228 Acc: 0.9516\n","\n","Epoch 77/85\n","----------\n","Train Loss: 0.6440 Acc: 0.9274\n","\n","Epoch 78/85\n","----------\n","Train Loss: 0.6152 Acc: 0.9470\n","\n","Epoch 79/85\n","----------\n","Train Loss: 0.6225 Acc: 0.9425\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.6118 Acc: 0.9531\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6164 Acc: 0.9516\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.6157 Acc: 0.9455\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.6651 Acc: 0.8896\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.6663 Acc: 0.8956\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.6694 Acc: 0.8911\n","\n","Training is completed in 6m 54s\n","Best train Acc: 0.971256\n","Training Fold 3/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9691 Acc: 0.5855\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7868 Acc: 0.7837\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.6795 Acc: 0.9047\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6608 Acc: 0.9017\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6560 Acc: 0.9077\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6527 Acc: 0.9153\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6366 Acc: 0.9289\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6154 Acc: 0.9455\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6269 Acc: 0.9334\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6270 Acc: 0.9304\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6428 Acc: 0.9077\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6258 Acc: 0.9395\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6272 Acc: 0.9365\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6317 Acc: 0.9274\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6405 Acc: 0.9228\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6152 Acc: 0.9425\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6273 Acc: 0.9334\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6326 Acc: 0.9380\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6360 Acc: 0.9274\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6259 Acc: 0.9349\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.6400 Acc: 0.9228\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6091 Acc: 0.9546\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6139 Acc: 0.9455\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6146 Acc: 0.9516\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6098 Acc: 0.9501\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6080 Acc: 0.9501\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.6000 Acc: 0.9576\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.6091 Acc: 0.9455\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.6096 Acc: 0.9501\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.6099 Acc: 0.9395\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.6235 Acc: 0.9440\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.6170 Acc: 0.9455\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.6082 Acc: 0.9637\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6347 Acc: 0.9259\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.6083 Acc: 0.9576\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.6177 Acc: 0.9410\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.6342 Acc: 0.9244\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6321 Acc: 0.9274\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.6327 Acc: 0.9198\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.6409 Acc: 0.9244\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.6375 Acc: 0.9304\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.6234 Acc: 0.9365\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.6036 Acc: 0.9546\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.6186 Acc: 0.9470\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.6366 Acc: 0.9259\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.6170 Acc: 0.9470\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.6076 Acc: 0.9576\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.5944 Acc: 0.9576\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.6078 Acc: 0.9607\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.6071 Acc: 0.9561\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.6133 Acc: 0.9486\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.6207 Acc: 0.9334\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.6248 Acc: 0.9380\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.6391 Acc: 0.9198\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.6296 Acc: 0.9304\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.6813 Acc: 0.8699\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.6611 Acc: 0.9017\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.6631 Acc: 0.8941\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.6183 Acc: 0.9410\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.6263 Acc: 0.9259\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.6392 Acc: 0.9123\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.6289 Acc: 0.9349\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.6271 Acc: 0.9319\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.6230 Acc: 0.9380\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.6229 Acc: 0.9440\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6130 Acc: 0.9455\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6349 Acc: 0.9198\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.6196 Acc: 0.9455\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.6116 Acc: 0.9455\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.6125 Acc: 0.9516\n","\n","Epoch 70/85\n","----------\n","Train Loss: 0.6100 Acc: 0.9440\n","\n","Epoch 71/85\n","----------\n","Train Loss: 0.6034 Acc: 0.9561\n","\n","Epoch 72/85\n","----------\n","Train Loss: 0.6005 Acc: 0.9607\n","\n","Epoch 73/85\n","----------\n","Train Loss: 0.6004 Acc: 0.9667\n","\n","Epoch 74/85\n","----------\n","Train Loss: 0.6063 Acc: 0.9455\n","\n","Epoch 75/85\n","----------\n","Train Loss: 0.6066 Acc: 0.9576\n","\n","Epoch 76/85\n","----------\n","Train Loss: 0.6079 Acc: 0.9546\n","\n","Epoch 77/85\n","----------\n","Train Loss: 0.5932 Acc: 0.9667\n","\n","Epoch 78/85\n","----------\n","Train Loss: 0.5971 Acc: 0.9667\n","\n","Epoch 79/85\n","----------\n","Train Loss: 0.6004 Acc: 0.9516\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.6089 Acc: 0.9455\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6177 Acc: 0.9455\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.6004 Acc: 0.9576\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.6019 Acc: 0.9561\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.6063 Acc: 0.9607\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.6131 Acc: 0.9486\n","\n","Training is completed in 6m 52s\n","Best train Acc: 0.966717\n","Training Fold 4/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9562 Acc: 0.6006\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7799 Acc: 0.7685\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.7248 Acc: 0.8563\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6541 Acc: 0.9183\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6301 Acc: 0.9289\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6139 Acc: 0.9531\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6235 Acc: 0.9349\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6534 Acc: 0.9153\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6431 Acc: 0.9213\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6257 Acc: 0.9380\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6379 Acc: 0.9228\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6203 Acc: 0.9410\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6487 Acc: 0.9153\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6388 Acc: 0.9244\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6372 Acc: 0.9244\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6345 Acc: 0.9470\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6171 Acc: 0.9410\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6157 Acc: 0.9516\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6035 Acc: 0.9501\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6050 Acc: 0.9592\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.6015 Acc: 0.9455\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6122 Acc: 0.9516\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6059 Acc: 0.9561\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6097 Acc: 0.9425\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6320 Acc: 0.9380\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6155 Acc: 0.9455\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.6226 Acc: 0.9319\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.6268 Acc: 0.9395\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.6162 Acc: 0.9470\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.5941 Acc: 0.9637\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.6229 Acc: 0.9455\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.6066 Acc: 0.9592\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.6246 Acc: 0.9334\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6257 Acc: 0.9349\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.6229 Acc: 0.9380\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.6264 Acc: 0.9349\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.6435 Acc: 0.9153\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6439 Acc: 0.9077\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.6266 Acc: 0.9289\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.6169 Acc: 0.9410\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.6113 Acc: 0.9561\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.6024 Acc: 0.9652\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.5960 Acc: 0.9592\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.6045 Acc: 0.9425\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.6082 Acc: 0.9440\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.6096 Acc: 0.9561\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.5982 Acc: 0.9652\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.6062 Acc: 0.9546\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.6161 Acc: 0.9501\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.6266 Acc: 0.9289\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.5997 Acc: 0.9516\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.6142 Acc: 0.9304\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.6137 Acc: 0.9470\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.6253 Acc: 0.9304\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.5968 Acc: 0.9682\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.6040 Acc: 0.9516\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.6001 Acc: 0.9546\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.6297 Acc: 0.9395\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.6283 Acc: 0.9319\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.6256 Acc: 0.9228\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.6208 Acc: 0.9289\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.6120 Acc: 0.9516\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.6448 Acc: 0.9198\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.6394 Acc: 0.9289\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.6434 Acc: 0.9092\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6370 Acc: 0.9259\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6229 Acc: 0.9334\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.6626 Acc: 0.8986\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.6234 Acc: 0.9289\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.6181 Acc: 0.9334\n","\n","Epoch 70/85\n","----------\n","Train Loss: 0.6373 Acc: 0.9274\n","\n","Epoch 71/85\n","----------\n","Train Loss: 0.6191 Acc: 0.9425\n","\n","Epoch 72/85\n","----------\n","Train Loss: 0.6049 Acc: 0.9425\n","\n","Epoch 73/85\n","----------\n","Train Loss: 0.5974 Acc: 0.9576\n","\n","Epoch 74/85\n","----------\n","Train Loss: 0.5959 Acc: 0.9682\n","\n","Epoch 75/85\n","----------\n","Train Loss: 0.5938 Acc: 0.9637\n","\n","Epoch 76/85\n","----------\n","Train Loss: 0.6314 Acc: 0.9304\n","\n","Epoch 77/85\n","----------\n","Train Loss: 0.6206 Acc: 0.9501\n","\n","Epoch 78/85\n","----------\n","Train Loss: 0.6094 Acc: 0.9455\n","\n","Epoch 79/85\n","----------\n","Train Loss: 0.6078 Acc: 0.9576\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.6080 Acc: 0.9531\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6111 Acc: 0.9470\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.5961 Acc: 0.9592\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.6212 Acc: 0.9380\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.5968 Acc: 0.9652\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.6083 Acc: 0.9440\n","\n","Training is completed in 6m 48s\n","Best train Acc: 0.968230\n","Training Fold 5/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9470 Acc: 0.5855\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7723 Acc: 0.7958\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.6711 Acc: 0.9047\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6655 Acc: 0.9017\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6439 Acc: 0.9289\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6314 Acc: 0.9244\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6400 Acc: 0.9349\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6291 Acc: 0.9319\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6327 Acc: 0.9410\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6555 Acc: 0.9032\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6596 Acc: 0.8986\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6403 Acc: 0.9259\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6343 Acc: 0.9289\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6411 Acc: 0.9274\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6193 Acc: 0.9531\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6046 Acc: 0.9622\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6143 Acc: 0.9425\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6078 Acc: 0.9486\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6161 Acc: 0.9380\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6202 Acc: 0.9319\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.6166 Acc: 0.9470\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6237 Acc: 0.9425\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6410 Acc: 0.9228\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6122 Acc: 0.9531\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6100 Acc: 0.9516\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6028 Acc: 0.9592\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.6160 Acc: 0.9531\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.5981 Acc: 0.9592\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.6052 Acc: 0.9516\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.6185 Acc: 0.9455\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.6280 Acc: 0.9349\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.6150 Acc: 0.9455\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.6014 Acc: 0.9607\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6119 Acc: 0.9410\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.5959 Acc: 0.9592\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.5992 Acc: 0.9637\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.5882 Acc: 0.9743\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6010 Acc: 0.9667\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.5842 Acc: 0.9697\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.5969 Acc: 0.9682\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.5987 Acc: 0.9516\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.6444 Acc: 0.9213\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.6921 Acc: 0.8654\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.6838 Acc: 0.8820\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.6620 Acc: 0.8941\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.6457 Acc: 0.9092\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.6207 Acc: 0.9486\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.6161 Acc: 0.9410\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.6049 Acc: 0.9576\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.6245 Acc: 0.9304\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.6091 Acc: 0.9546\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.6023 Acc: 0.9667\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.6022 Acc: 0.9531\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.5963 Acc: 0.9713\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.5997 Acc: 0.9622\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.6168 Acc: 0.9380\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.6351 Acc: 0.9198\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.6290 Acc: 0.9259\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.6399 Acc: 0.9168\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.6600 Acc: 0.8896\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.6404 Acc: 0.9213\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.6346 Acc: 0.9198\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.6263 Acc: 0.9289\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.6262 Acc: 0.9304\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.6212 Acc: 0.9440\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6240 Acc: 0.9395\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6566 Acc: 0.8986\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.6348 Acc: 0.9304\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.6189 Acc: 0.9425\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.6049 Acc: 0.9546\n","\n","Epoch 70/85\n","----------\n","Train Loss: 0.6245 Acc: 0.9410\n","\n","Epoch 71/85\n","----------\n","Train Loss: 0.6200 Acc: 0.9395\n","\n","Epoch 72/85\n","----------\n","Train Loss: 0.6102 Acc: 0.9486\n","\n","Epoch 73/85\n","----------\n","Train Loss: 0.6164 Acc: 0.9440\n","\n","Epoch 74/85\n","----------\n","Train Loss: 0.6023 Acc: 0.9546\n","\n","Epoch 75/85\n","----------\n","Train Loss: 0.6082 Acc: 0.9531\n","\n","Epoch 76/85\n","----------\n","Train Loss: 0.6125 Acc: 0.9470\n","\n","Epoch 77/85\n","----------\n","Train Loss: 0.6207 Acc: 0.9425\n","\n","Epoch 78/85\n","----------\n","Train Loss: 0.6061 Acc: 0.9486\n","\n","Epoch 79/85\n","----------\n","Train Loss: 0.6038 Acc: 0.9561\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.6067 Acc: 0.9546\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6099 Acc: 0.9501\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.6045 Acc: 0.9486\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.5929 Acc: 0.9697\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.6034 Acc: 0.9667\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.5955 Acc: 0.9667\n","\n","Training is completed in 6m 24s\n","Best train Acc: 0.974281\n","Training Fold 6/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9657 Acc: 0.5582\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7917 Acc: 0.7640\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.6902 Acc: 0.9138\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6521 Acc: 0.9183\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6546 Acc: 0.9077\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6397 Acc: 0.9289\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6295 Acc: 0.9425\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6164 Acc: 0.9470\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6231 Acc: 0.9380\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6213 Acc: 0.9395\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6229 Acc: 0.9425\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6296 Acc: 0.9365\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6149 Acc: 0.9410\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6442 Acc: 0.9228\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6388 Acc: 0.9244\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6134 Acc: 0.9592\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6081 Acc: 0.9546\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6127 Acc: 0.9516\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6099 Acc: 0.9531\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6221 Acc: 0.9455\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.5992 Acc: 0.9592\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6221 Acc: 0.9380\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6241 Acc: 0.9440\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6125 Acc: 0.9531\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6363 Acc: 0.9259\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6330 Acc: 0.9198\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.6281 Acc: 0.9395\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.6192 Acc: 0.9380\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.6070 Acc: 0.9546\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.6173 Acc: 0.9425\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.6362 Acc: 0.9289\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.6153 Acc: 0.9516\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.6085 Acc: 0.9531\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6135 Acc: 0.9531\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.6029 Acc: 0.9667\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.5989 Acc: 0.9546\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.6130 Acc: 0.9455\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6289 Acc: 0.9274\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.6192 Acc: 0.9395\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.6123 Acc: 0.9531\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.6104 Acc: 0.9592\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.6079 Acc: 0.9531\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.6002 Acc: 0.9607\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.5916 Acc: 0.9743\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.6013 Acc: 0.9622\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.5947 Acc: 0.9713\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.5984 Acc: 0.9637\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.5948 Acc: 0.9637\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.6255 Acc: 0.9365\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.6079 Acc: 0.9592\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.5940 Acc: 0.9607\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.5956 Acc: 0.9592\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.5976 Acc: 0.9652\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.6213 Acc: 0.9365\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.6246 Acc: 0.9304\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.6284 Acc: 0.9319\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.6229 Acc: 0.9486\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.6410 Acc: 0.9123\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.6186 Acc: 0.9486\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.6142 Acc: 0.9470\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.6262 Acc: 0.9349\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.6447 Acc: 0.9153\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.6315 Acc: 0.9274\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.6015 Acc: 0.9561\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.6948 Acc: 0.8684\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6317 Acc: 0.9380\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6182 Acc: 0.9349\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.6166 Acc: 0.9455\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.6561 Acc: 0.9017\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.6432 Acc: 0.9168\n","\n","Epoch 70/85\n","----------\n","Train Loss: 0.7122 Acc: 0.8396\n","\n","Epoch 71/85\n","----------\n","Train Loss: 0.6680 Acc: 0.8926\n","\n","Epoch 72/85\n","----------\n","Train Loss: 0.6860 Acc: 0.8714\n","\n","Epoch 73/85\n","----------\n","Train Loss: 0.6540 Acc: 0.9077\n","\n","Epoch 74/85\n","----------\n","Train Loss: 0.6186 Acc: 0.9455\n","\n","Epoch 75/85\n","----------\n","Train Loss: 0.6309 Acc: 0.9259\n","\n","Epoch 76/85\n","----------\n","Train Loss: 0.6228 Acc: 0.9319\n","\n","Epoch 77/85\n","----------\n","Train Loss: 0.6064 Acc: 0.9592\n","\n","Epoch 78/85\n","----------\n","Train Loss: 0.6041 Acc: 0.9486\n","\n","Epoch 79/85\n","----------\n","Train Loss: 0.6026 Acc: 0.9531\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.6072 Acc: 0.9622\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6018 Acc: 0.9607\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.6107 Acc: 0.9592\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.6034 Acc: 0.9622\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.6058 Acc: 0.9592\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.6012 Acc: 0.9652\n","\n","Training is completed in 6m 28s\n","Best train Acc: 0.974281\n","Training Fold 7/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9578 Acc: 0.5688\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7773 Acc: 0.8003\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.6802 Acc: 0.8865\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6679 Acc: 0.8941\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6841 Acc: 0.8835\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6656 Acc: 0.9047\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6434 Acc: 0.9228\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6197 Acc: 0.9365\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6138 Acc: 0.9470\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6226 Acc: 0.9440\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6122 Acc: 0.9470\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6183 Acc: 0.9365\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6190 Acc: 0.9395\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6068 Acc: 0.9576\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6191 Acc: 0.9410\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6063 Acc: 0.9622\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6025 Acc: 0.9652\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6111 Acc: 0.9455\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6027 Acc: 0.9637\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6105 Acc: 0.9561\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.6147 Acc: 0.9455\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6441 Acc: 0.9198\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6182 Acc: 0.9334\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6005 Acc: 0.9576\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6025 Acc: 0.9501\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6027 Acc: 0.9607\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.6008 Acc: 0.9592\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.6127 Acc: 0.9501\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.6028 Acc: 0.9576\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.6120 Acc: 0.9546\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.6008 Acc: 0.9652\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.6067 Acc: 0.9531\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.5960 Acc: 0.9637\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6116 Acc: 0.9425\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.6093 Acc: 0.9486\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.6151 Acc: 0.9470\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.6135 Acc: 0.9470\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6130 Acc: 0.9501\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.6332 Acc: 0.9259\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.6097 Acc: 0.9516\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.6275 Acc: 0.9349\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.6551 Acc: 0.8956\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.6093 Acc: 0.9531\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.6042 Acc: 0.9607\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.6288 Acc: 0.9319\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.6215 Acc: 0.9380\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.6042 Acc: 0.9516\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.6166 Acc: 0.9365\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.6247 Acc: 0.9349\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.6074 Acc: 0.9546\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.6125 Acc: 0.9470\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.6037 Acc: 0.9607\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.6054 Acc: 0.9501\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.6008 Acc: 0.9667\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.6082 Acc: 0.9546\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.5886 Acc: 0.9728\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.6024 Acc: 0.9637\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.6043 Acc: 0.9516\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.6068 Acc: 0.9531\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.6046 Acc: 0.9576\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.6031 Acc: 0.9576\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.6433 Acc: 0.9213\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.6245 Acc: 0.9486\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.6007 Acc: 0.9607\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.5977 Acc: 0.9561\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6046 Acc: 0.9592\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6027 Acc: 0.9561\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.5913 Acc: 0.9713\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.5860 Acc: 0.9743\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.5827 Acc: 0.9818\n","\n","Epoch 70/85\n","----------\n","Train Loss: 0.5953 Acc: 0.9576\n","\n","Epoch 71/85\n","----------\n","Train Loss: 0.6213 Acc: 0.9455\n","\n","Epoch 72/85\n","----------\n","Train Loss: 0.6406 Acc: 0.9168\n","\n","Epoch 73/85\n","----------\n","Train Loss: 0.7100 Acc: 0.8502\n","\n","Epoch 74/85\n","----------\n","Train Loss: 0.6990 Acc: 0.8502\n","\n","Epoch 75/85\n","----------\n","Train Loss: 0.6923 Acc: 0.8654\n","\n","Epoch 76/85\n","----------\n","Train Loss: 0.6320 Acc: 0.9213\n","\n","Epoch 77/85\n","----------\n","Train Loss: 0.6119 Acc: 0.9425\n","\n","Epoch 78/85\n","----------\n","Train Loss: 0.6176 Acc: 0.9425\n","\n","Epoch 79/85\n","----------\n","Train Loss: 0.6273 Acc: 0.9289\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.6387 Acc: 0.9183\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6201 Acc: 0.9410\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.5862 Acc: 0.9667\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.6111 Acc: 0.9410\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.6122 Acc: 0.9682\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.6015 Acc: 0.9486\n","\n","Training is completed in 6m 29s\n","Best train Acc: 0.981846\n","Training Fold 8/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9808 Acc: 0.5688\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7999 Acc: 0.7791\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.6774 Acc: 0.8971\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6518 Acc: 0.9138\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6570 Acc: 0.9092\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6530 Acc: 0.9153\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6452 Acc: 0.9183\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6535 Acc: 0.9153\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6538 Acc: 0.9047\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6484 Acc: 0.9138\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6348 Acc: 0.9289\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6332 Acc: 0.9259\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6502 Acc: 0.9062\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6369 Acc: 0.9244\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6495 Acc: 0.9153\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6328 Acc: 0.9259\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6264 Acc: 0.9319\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6208 Acc: 0.9470\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6376 Acc: 0.9289\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6065 Acc: 0.9531\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.6072 Acc: 0.9440\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6111 Acc: 0.9561\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6197 Acc: 0.9395\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6047 Acc: 0.9622\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6070 Acc: 0.9576\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6131 Acc: 0.9501\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.6006 Acc: 0.9637\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.6223 Acc: 0.9334\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.6099 Acc: 0.9576\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.6043 Acc: 0.9516\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.5991 Acc: 0.9622\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.5998 Acc: 0.9576\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.5960 Acc: 0.9743\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6051 Acc: 0.9455\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.6533 Acc: 0.8971\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.6847 Acc: 0.8790\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.6667 Acc: 0.8896\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6451 Acc: 0.9168\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.6386 Acc: 0.9123\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.6260 Acc: 0.9410\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.6202 Acc: 0.9470\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.6216 Acc: 0.9425\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.6152 Acc: 0.9440\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.6161 Acc: 0.9410\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.6078 Acc: 0.9516\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.6333 Acc: 0.9289\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.6015 Acc: 0.9592\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.6114 Acc: 0.9455\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.6275 Acc: 0.9259\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.6246 Acc: 0.9349\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.5997 Acc: 0.9546\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.5988 Acc: 0.9622\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.6084 Acc: 0.9561\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.6138 Acc: 0.9501\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.6092 Acc: 0.9546\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.6210 Acc: 0.9395\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.6073 Acc: 0.9440\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.6041 Acc: 0.9622\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.6011 Acc: 0.9607\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.6052 Acc: 0.9561\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.6013 Acc: 0.9531\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.6084 Acc: 0.9622\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.5872 Acc: 0.9637\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.5979 Acc: 0.9637\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.6004 Acc: 0.9682\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6083 Acc: 0.9576\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6292 Acc: 0.9380\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.6399 Acc: 0.9213\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.6320 Acc: 0.9319\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.5990 Acc: 0.9546\n","\n","Epoch 70/85\n","----------\n","Train Loss: 0.6008 Acc: 0.9652\n","\n","Epoch 71/85\n","----------\n","Train Loss: 0.6035 Acc: 0.9622\n","\n","Epoch 72/85\n","----------\n","Train Loss: 0.6030 Acc: 0.9622\n","\n","Epoch 73/85\n","----------\n","Train Loss: 0.6120 Acc: 0.9516\n","\n","Epoch 74/85\n","----------\n","Train Loss: 0.6032 Acc: 0.9546\n","\n","Epoch 75/85\n","----------\n","Train Loss: 0.6151 Acc: 0.9425\n","\n","Epoch 76/85\n","----------\n","Train Loss: 0.6033 Acc: 0.9561\n","\n","Epoch 77/85\n","----------\n","Train Loss: 0.5991 Acc: 0.9652\n","\n","Epoch 78/85\n","----------\n","Train Loss: 0.6438 Acc: 0.9107\n","\n","Epoch 79/85\n","----------\n","Train Loss: 0.6106 Acc: 0.9486\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.6155 Acc: 0.9516\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6251 Acc: 0.9334\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.6385 Acc: 0.9183\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.6148 Acc: 0.9486\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.6195 Acc: 0.9425\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.6344 Acc: 0.9259\n","\n","Training is completed in 6m 39s\n","Best train Acc: 0.974281\n","Training Fold 9/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9502 Acc: 0.6021\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7799 Acc: 0.7746\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.6837 Acc: 0.9002\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6598 Acc: 0.9138\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6390 Acc: 0.9198\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6424 Acc: 0.9259\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6418 Acc: 0.9123\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6341 Acc: 0.9349\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6168 Acc: 0.9380\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6248 Acc: 0.9395\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6361 Acc: 0.9289\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6516 Acc: 0.9062\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6381 Acc: 0.9304\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6390 Acc: 0.9198\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6100 Acc: 0.9395\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6226 Acc: 0.9319\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6442 Acc: 0.9138\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6734 Acc: 0.8911\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6307 Acc: 0.9304\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6248 Acc: 0.9395\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.6230 Acc: 0.9395\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6216 Acc: 0.9455\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6146 Acc: 0.9410\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6096 Acc: 0.9561\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6042 Acc: 0.9516\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6024 Acc: 0.9637\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.5991 Acc: 0.9682\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.5980 Acc: 0.9592\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.5941 Acc: 0.9713\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.6056 Acc: 0.9622\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.5941 Acc: 0.9713\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.6154 Acc: 0.9289\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.6085 Acc: 0.9561\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6051 Acc: 0.9576\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.6066 Acc: 0.9516\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.6017 Acc: 0.9576\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.5926 Acc: 0.9682\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6085 Acc: 0.9501\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.5991 Acc: 0.9652\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.6042 Acc: 0.9501\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.6083 Acc: 0.9470\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.6269 Acc: 0.9365\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.6404 Acc: 0.9183\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.6374 Acc: 0.9274\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.6518 Acc: 0.9123\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.6318 Acc: 0.9198\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.6151 Acc: 0.9440\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.6384 Acc: 0.9244\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.6312 Acc: 0.9213\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.6199 Acc: 0.9395\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.6433 Acc: 0.9168\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.6561 Acc: 0.9107\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.6352 Acc: 0.9138\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.6214 Acc: 0.9349\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.6113 Acc: 0.9440\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.6119 Acc: 0.9486\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.6065 Acc: 0.9501\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.6187 Acc: 0.9410\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.6127 Acc: 0.9516\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.6364 Acc: 0.9304\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.6313 Acc: 0.9410\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.6268 Acc: 0.9410\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.6261 Acc: 0.9349\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.6337 Acc: 0.9259\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.6192 Acc: 0.9410\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6007 Acc: 0.9743\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6074 Acc: 0.9607\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.6045 Acc: 0.9561\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.6013 Acc: 0.9637\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.6044 Acc: 0.9516\n","\n","Epoch 70/85\n","----------\n","Train Loss: 0.5882 Acc: 0.9728\n","\n","Epoch 71/85\n","----------\n","Train Loss: 0.5919 Acc: 0.9743\n","\n","Epoch 72/85\n","----------\n","Train Loss: 0.5984 Acc: 0.9637\n","\n","Epoch 73/85\n","----------\n","Train Loss: 0.5987 Acc: 0.9516\n","\n","Epoch 74/85\n","----------\n","Train Loss: 0.5949 Acc: 0.9622\n","\n","Epoch 75/85\n","----------\n","Train Loss: 0.6130 Acc: 0.9440\n","\n","Epoch 76/85\n","----------\n","Train Loss: 0.6071 Acc: 0.9607\n","\n","Epoch 77/85\n","----------\n","Train Loss: 0.6160 Acc: 0.9516\n","\n","Epoch 78/85\n","----------\n","Train Loss: 0.6014 Acc: 0.9592\n","\n","Epoch 79/85\n","----------\n","Train Loss: 0.6098 Acc: 0.9440\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.6200 Acc: 0.9516\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6710 Acc: 0.8850\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.6801 Acc: 0.8684\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.6307 Acc: 0.9410\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.6328 Acc: 0.9304\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.6607 Acc: 0.8941\n","\n","Training is completed in 6m 38s\n","Best train Acc: 0.974281\n","Training Fold 10/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Epoch 0/85\n","----------\n","Train Loss: 0.9667 Acc: 0.5719\n","\n","Epoch 1/85\n","----------\n","Train Loss: 0.7733 Acc: 0.8048\n","\n","Epoch 2/85\n","----------\n","Train Loss: 0.6735 Acc: 0.9017\n","\n","Epoch 3/85\n","----------\n","Train Loss: 0.6612 Acc: 0.9168\n","\n","Epoch 4/85\n","----------\n","Train Loss: 0.6395 Acc: 0.9349\n","\n","Epoch 5/85\n","----------\n","Train Loss: 0.6423 Acc: 0.9198\n","\n","Epoch 6/85\n","----------\n","Train Loss: 0.6358 Acc: 0.9228\n","\n","Epoch 7/85\n","----------\n","Train Loss: 0.6333 Acc: 0.9349\n","\n","Epoch 8/85\n","----------\n","Train Loss: 0.6354 Acc: 0.9259\n","\n","Epoch 9/85\n","----------\n","Train Loss: 0.6403 Acc: 0.9123\n","\n","Epoch 10/85\n","----------\n","Train Loss: 0.6342 Acc: 0.9259\n","\n","Epoch 11/85\n","----------\n","Train Loss: 0.6276 Acc: 0.9334\n","\n","Epoch 12/85\n","----------\n","Train Loss: 0.6498 Acc: 0.9198\n","\n","Epoch 13/85\n","----------\n","Train Loss: 0.6205 Acc: 0.9470\n","\n","Epoch 14/85\n","----------\n","Train Loss: 0.6249 Acc: 0.9365\n","\n","Epoch 15/85\n","----------\n","Train Loss: 0.6320 Acc: 0.9228\n","\n","Epoch 16/85\n","----------\n","Train Loss: 0.6436 Acc: 0.9183\n","\n","Epoch 17/85\n","----------\n","Train Loss: 0.6059 Acc: 0.9622\n","\n","Epoch 18/85\n","----------\n","Train Loss: 0.6321 Acc: 0.9198\n","\n","Epoch 19/85\n","----------\n","Train Loss: 0.6399 Acc: 0.9274\n","\n","Epoch 20/85\n","----------\n","Train Loss: 0.6159 Acc: 0.9501\n","\n","Epoch 21/85\n","----------\n","Train Loss: 0.6123 Acc: 0.9561\n","\n","Epoch 22/85\n","----------\n","Train Loss: 0.6074 Acc: 0.9576\n","\n","Epoch 23/85\n","----------\n","Train Loss: 0.6011 Acc: 0.9622\n","\n","Epoch 24/85\n","----------\n","Train Loss: 0.6035 Acc: 0.9607\n","\n","Epoch 25/85\n","----------\n","Train Loss: 0.6042 Acc: 0.9728\n","\n","Epoch 26/85\n","----------\n","Train Loss: 0.6176 Acc: 0.9516\n","\n","Epoch 27/85\n","----------\n","Train Loss: 0.6034 Acc: 0.9531\n","\n","Epoch 28/85\n","----------\n","Train Loss: 0.6058 Acc: 0.9592\n","\n","Epoch 29/85\n","----------\n","Train Loss: 0.5997 Acc: 0.9637\n","\n","Epoch 30/85\n","----------\n","Train Loss: 0.5994 Acc: 0.9622\n","\n","Epoch 31/85\n","----------\n","Train Loss: 0.6069 Acc: 0.9576\n","\n","Epoch 32/85\n","----------\n","Train Loss: 0.6184 Acc: 0.9546\n","\n","Epoch 33/85\n","----------\n","Train Loss: 0.6246 Acc: 0.9334\n","\n","Epoch 34/85\n","----------\n","Train Loss: 0.6114 Acc: 0.9486\n","\n","Epoch 35/85\n","----------\n","Train Loss: 0.6201 Acc: 0.9455\n","\n","Epoch 36/85\n","----------\n","Train Loss: 0.6182 Acc: 0.9470\n","\n","Epoch 37/85\n","----------\n","Train Loss: 0.6063 Acc: 0.9561\n","\n","Epoch 38/85\n","----------\n","Train Loss: 0.6167 Acc: 0.9531\n","\n","Epoch 39/85\n","----------\n","Train Loss: 0.5986 Acc: 0.9637\n","\n","Epoch 40/85\n","----------\n","Train Loss: 0.6085 Acc: 0.9516\n","\n","Epoch 41/85\n","----------\n","Train Loss: 0.5993 Acc: 0.9682\n","\n","Epoch 42/85\n","----------\n","Train Loss: 0.6037 Acc: 0.9561\n","\n","Epoch 43/85\n","----------\n","Train Loss: 0.6131 Acc: 0.9576\n","\n","Epoch 44/85\n","----------\n","Train Loss: 0.5899 Acc: 0.9607\n","\n","Epoch 45/85\n","----------\n","Train Loss: 0.5970 Acc: 0.9592\n","\n","Epoch 46/85\n","----------\n","Train Loss: 0.5983 Acc: 0.9637\n","\n","Epoch 47/85\n","----------\n","Train Loss: 0.5882 Acc: 0.9697\n","\n","Epoch 48/85\n","----------\n","Train Loss: 0.5935 Acc: 0.9546\n","\n","Epoch 49/85\n","----------\n","Train Loss: 0.5943 Acc: 0.9637\n","\n","Epoch 50/85\n","----------\n","Train Loss: 0.6053 Acc: 0.9470\n","\n","Epoch 51/85\n","----------\n","Train Loss: 0.5991 Acc: 0.9622\n","\n","Epoch 52/85\n","----------\n","Train Loss: 0.6005 Acc: 0.9607\n","\n","Epoch 53/85\n","----------\n","Train Loss: 0.5960 Acc: 0.9652\n","\n","Epoch 54/85\n","----------\n","Train Loss: 0.6005 Acc: 0.9607\n","\n","Epoch 55/85\n","----------\n","Train Loss: 0.6058 Acc: 0.9592\n","\n","Epoch 56/85\n","----------\n","Train Loss: 0.6004 Acc: 0.9546\n","\n","Epoch 57/85\n","----------\n","Train Loss: 0.6138 Acc: 0.9380\n","\n","Epoch 58/85\n","----------\n","Train Loss: 0.6376 Acc: 0.9289\n","\n","Epoch 59/85\n","----------\n","Train Loss: 0.6492 Acc: 0.9138\n","\n","Epoch 60/85\n","----------\n","Train Loss: 0.6846 Acc: 0.8850\n","\n","Epoch 61/85\n","----------\n","Train Loss: 0.7097 Acc: 0.8517\n","\n","Epoch 62/85\n","----------\n","Train Loss: 0.6955 Acc: 0.8593\n","\n","Epoch 63/85\n","----------\n","Train Loss: 0.6780 Acc: 0.8911\n","\n","Epoch 64/85\n","----------\n","Train Loss: 0.6295 Acc: 0.9334\n","\n","Epoch 65/85\n","----------\n","Train Loss: 0.6173 Acc: 0.9501\n","\n","Epoch 66/85\n","----------\n","Train Loss: 0.6108 Acc: 0.9440\n","\n","Epoch 67/85\n","----------\n","Train Loss: 0.6438 Acc: 0.9198\n","\n","Epoch 68/85\n","----------\n","Train Loss: 0.6397 Acc: 0.9213\n","\n","Epoch 69/85\n","----------\n","Train Loss: 0.6096 Acc: 0.9516\n","\n","Epoch 70/85\n","----------\n","Train Loss: 0.6178 Acc: 0.9501\n","\n","Epoch 71/85\n","----------\n","Train Loss: 0.6072 Acc: 0.9486\n","\n","Epoch 72/85\n","----------\n","Train Loss: 0.6153 Acc: 0.9440\n","\n","Epoch 73/85\n","----------\n","Train Loss: 0.6208 Acc: 0.9334\n","\n","Epoch 74/85\n","----------\n","Train Loss: 0.6201 Acc: 0.9455\n","\n","Epoch 75/85\n","----------\n","Train Loss: 0.6106 Acc: 0.9622\n","\n","Epoch 76/85\n","----------\n","Train Loss: 0.6107 Acc: 0.9440\n","\n","Epoch 77/85\n","----------\n","Train Loss: 0.5988 Acc: 0.9561\n","\n","Epoch 78/85\n","----------\n","Train Loss: 0.6111 Acc: 0.9531\n","\n","Epoch 79/85\n","----------\n","Train Loss: 0.6308 Acc: 0.9349\n","\n","Epoch 80/85\n","----------\n","Train Loss: 0.5973 Acc: 0.9607\n","\n","Epoch 81/85\n","----------\n","Train Loss: 0.6029 Acc: 0.9546\n","\n","Epoch 82/85\n","----------\n","Train Loss: 0.6028 Acc: 0.9713\n","\n","Epoch 83/85\n","----------\n","Train Loss: 0.5987 Acc: 0.9637\n","\n","Epoch 84/85\n","----------\n","Train Loss: 0.5941 Acc: 0.9637\n","\n","Epoch 85/85\n","----------\n","Train Loss: 0.5935 Acc: 0.9637\n","\n","Training is completed in 6m 34s\n","Best train Acc: 0.972769\n","Total training time for 10 folds: 66m 12s\n"]}],"source":["# Train K models, each on the entire Dataset_New\n","trained_model_states = Train_Model_Final_KFold(model, criterion, optimizer, Dataset_New,\n","                                               num_epochs = best_params_for_k[\"num_epochs\"],\n","                                               scheduler = scheduler,\n","                                               scheduler_type = scheduler_types, # Pass the scheduler type\n","                                               K= K) # gamma1 is not used in the training loop here"]},{"cell_type":"code","execution_count":null,"id":"72990fe3-8f77-4503-b7df-921b775692be","metadata":{"id":"72990fe3-8f77-4503-b7df-921b775692be"},"outputs":[],"source":["#import numpy as np\n","#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","#import torch\n","\n","def evaluate_model_for_k(trained_model_states, Test_dataloader, K, class_names):\n","\n","    fold_metrics = []\n","    all_probs_accumulated = [] # To store probabilities for AUC calculation\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    for fold, model_state_dict in enumerate(trained_model_states):\n","        print(f\"Evaluating Fold {fold + 1}/{K}\")\n","\n","        # Create a new model instance and load the trained weights for this fold\n","        model, _, _ = Model_ResNet101_PyTorch(learning_rate=best_params_for_k[\"learning_rate\"],\n","                                              dropout_rate= best_params_for_k[\"dropout_rate\"])\n","\n","        model.load_state_dict(model_state_dict)\n","        model.to(device)\n","        model.eval()\n","\n","        all_preds_fold = []\n","        all_labels_fold = []\n","        all_probs_fold = [] # To store probabilities for this fold\n","\n","        with torch.no_grad():  # Disable gradient calculation during evaluation\n","            for inputs, labels in Test_dataloader:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                outputs = model(inputs)\n","                probs = outputs # Determines the probabilities used for calculating the auc score values\n","                _, preds = torch.max(outputs, 1)\n","                all_preds_fold.extend(preds.cpu().numpy())\n","                all_labels_fold.extend(labels.cpu().numpy())\n","\n","                all_probs_fold.extend(probs.cpu().numpy())\n","\n","        all_probs_accumulated.extend(all_probs_fold)\n","\n","        # Calculate overall metrics for this fold's evaluation\n","        metrics_this_fold = {}\n","        metrics_this_fold['accuracy'] = accuracy_score(all_labels_fold, all_preds_fold)\n","        metrics_this_fold['precision'] = precision_score(all_labels_fold, all_preds_fold, average='macro', zero_division=0)\n","        metrics_this_fold['recall'] = recall_score(all_labels_fold,all_preds_fold, average='macro', zero_division=0) # Should be all_labels_fold\n","        metrics_this_fold['f1-score'] = f1_score(all_labels_fold, all_preds_fold, average='macro', zero_division=0)\n","\n","        # Calculate per-class metrics for this fold's evaluation\n","        per_class_metrics_this_fold = {}\n","        cm_this_fold = confusion_matrix(all_labels_fold, all_preds_fold)\n","\n","        for i, class_name in enumerate(class_names):\n","            # Handle potential errors if a class is not present in the fold's labels/predictions\n","            tp = cm_this_fold[i, i] if i < cm_this_fold.shape[0] and i < cm_this_fold.shape[1] else 0\n","\n","            # Ensure column and row sums are within bounds\n","            fp = np.sum(cm_this_fold[:, i]) - tp if i < cm_this_fold.shape[1] else 0\n","            fn = np.sum(cm_this_fold[i, :]) - tp if i < cm_this_fold.shape[0] else 0\n","\n","            # Calculate precision, recall, and f1-score for the class\n","            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n","            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n","            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n","\n","            per_class_metrics_this_fold[class_name] = {\n","                'precision': precision,\n","                'recall': recall,\n","                'f1-score': f1\n","            }\n","\n","        fold_metrics.append({'overall': metrics_this_fold, 'per_class': per_class_metrics_this_fold})\n","\n","    # Calculate mean and standard deviation of overall metrics across all folds\n","    overall_metrics_across_folds = {metric: [f['overall'][metric] for f in fold_metrics if not np.isnan(f['overall'][metric])] for metric in ['accuracy', 'precision', 'recall', 'f1-score']} # Removed 'auc'\n","\n","    mean_overall_metrics = {metric: np.mean(values) if values else np.nan for metric, values in overall_metrics_across_folds.items()}\n","    std_overall_metrics = {metric: np.std(values) if values else np.nan for metric, values in overall_metrics_across_folds.items()}\n","\n","\n","    # Calculate average per-class metrics across all folds\n","    per_class_metrics_across_folds = {\n","        class_name: {\n","            metric: [fold_data['per_class'][class_name][metric] for fold_data in fold_metrics]\n","            for metric in ['precision', 'recall', 'f1-score']\n","        }\n","        for class_name in class_names\n","    }\n","\n","    mean_per_class_metrics = {\n","        class_name: {\n","            metric: np.mean(values)\n","            for metric, values in metrics.items()\n","        }\n","        for class_name, metrics in per_class_metrics_across_folds.items()\n","    }\n","\n","    std_per_class_metrics = {\n","        class_name: {\n","            metric: np.std(values)\n","            for metric, values in metrics.items()\n","        }\n","        for class_name, metrics in per_class_metrics_across_folds.items()\n","    }\n","\n","\n","    return {\n","        'fold_metrics': fold_metrics,\n","        'mean_overall_metrics': mean_overall_metrics,\n","        'std_overall_metrics': std_overall_metrics,\n","        'mean_per_class_metrics': mean_per_class_metrics, # Add mean per-class metrics\n","        'std_per_class_metrics': std_per_class_metrics # Add standard deviation of per-class metrics\n","        }"]},{"cell_type":"code","execution_count":null,"id":"345f8772-3848-40f0-a1b5-929d519636d0","metadata":{"id":"345f8772-3848-40f0-a1b5-929d519636d0","outputId":"1f365db9-0213-438a-f4e5-75ccc5008936"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluating Fold 1/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Evaluating Fold 2/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Evaluating Fold 3/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Evaluating Fold 4/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Evaluating Fold 5/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Evaluating Fold 6/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Evaluating Fold 7/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Evaluating Fold 8/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Evaluating Fold 9/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n","Evaluating Fold 10/10\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n","            ReLU-313          [-1, 512, 14, 14]               0\n","          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n","            ReLU-316            [-1, 512, 7, 7]               0\n","          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n","          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n","            ReLU-321           [-1, 2048, 7, 7]               0\n","      Bottleneck-322           [-1, 2048, 7, 7]               0\n","          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n","            ReLU-325            [-1, 512, 7, 7]               0\n","          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n","            ReLU-328            [-1, 512, 7, 7]               0\n","          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n","            ReLU-331           [-1, 2048, 7, 7]               0\n","      Bottleneck-332           [-1, 2048, 7, 7]               0\n","          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n","            ReLU-335            [-1, 512, 7, 7]               0\n","          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n","            ReLU-338            [-1, 512, 7, 7]               0\n","          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n","            ReLU-341           [-1, 2048, 7, 7]               0\n","      Bottleneck-342           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n","          Linear-344                    [-1, 3]           6,147\n","         Dropout-345                    [-1, 3]               0\n","         Softmax-346                    [-1, 3]               0\n","================================================================\n","Total params: 42,506,307\n","Trainable params: 41,061,379\n","Non-trainable params: 1,444,928\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 429.72\n","Params size (MB): 162.15\n","Estimated Total Size (MB): 592.45\n","----------------------------------------------------------------\n"]}],"source":["# Evaluate each of the K trained models on the Test_dataloader\n","metrics_k = evaluate_model_for_k(trained_model_states, Test_dataloader, K, class_names)"]},{"cell_type":"code","execution_count":null,"id":"fd6d11d5-bc95-4ad4-91d2-2d6dd695dfed","metadata":{"id":"fd6d11d5-bc95-4ad4-91d2-2d6dd695dfed","outputId":"fc542b6b-6939-472b-a072-3d4319651521"},"outputs":[{"name":"stdout","output_type":"stream","text":["Metrics per Fold (evaluated on Test_dataset):\n","\n","--- Fold 1 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.8189655172413793\n","    Precision: 0.7946081504702195\n","    Recall: 0.8267195767195767\n","    F1-Score: 0.8080175424048942\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.896551724137931\n","      Recall: 0.8253968253968254\n","      F1-score: 0.8595041322314049\n","    Class Malignant:\n","      Precision: 0.7272727272727273\n","      Recall: 0.75\n","      F1-score: 0.7384615384615384\n","    Class Normal:\n","      Precision: 0.76\n","      Recall: 0.9047619047619048\n","      F1-score: 0.8260869565217391\n","\n","--- Fold 2 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.8275862068965517\n","    Precision: 0.8618954248366012\n","    Recall: 0.7794312169312169\n","    F1-Score: 0.8100868112309759\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.7866666666666666\n","      Recall: 0.9365079365079365\n","      F1-score: 0.8550724637681159\n","    Class Malignant:\n","      Precision: 0.9166666666666666\n","      Recall: 0.6875\n","      F1-score: 0.7857142857142857\n","    Class Normal:\n","      Precision: 0.8823529411764706\n","      Recall: 0.7142857142857143\n","      F1-score: 0.7894736842105262\n","\n","--- Fold 3 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.8448275862068966\n","    Precision: 0.8395328028632602\n","    Recall: 0.8316798941798943\n","    F1-Score: 0.8339342188488299\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.9016393442622951\n","      Recall: 0.873015873015873\n","      F1-score: 0.8870967741935485\n","    Class Malignant:\n","      Precision: 0.7222222222222222\n","      Recall: 0.8125\n","      F1-score: 0.7647058823529411\n","    Class Normal:\n","      Precision: 0.8947368421052632\n","      Recall: 0.8095238095238095\n","      F1-score: 0.8500000000000001\n","\n","--- Fold 4 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.853448275862069\n","    Precision: 0.8471917240033182\n","    Recall: 0.8427579365079364\n","    F1-Score: 0.8423394369393581\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.8636363636363636\n","      Recall: 0.9047619047619048\n","      F1-score: 0.8837209302325582\n","    Class Malignant:\n","      Precision: 0.8518518518518519\n","      Recall: 0.71875\n","      F1-score: 0.7796610169491525\n","    Class Normal:\n","      Precision: 0.8260869565217391\n","      Recall: 0.9047619047619048\n","      F1-score: 0.8636363636363636\n","\n","--- Fold 5 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.8448275862068966\n","    Precision: 0.8393541324575807\n","    Recall: 0.8531746031746031\n","    F1-Score: 0.8443056639777952\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.8571428571428571\n","      Recall: 0.8571428571428571\n","      F1-score: 0.8571428571428571\n","    Class Malignant:\n","      Precision: 0.8275862068965517\n","      Recall: 0.75\n","      F1-score: 0.7868852459016394\n","    Class Normal:\n","      Precision: 0.8333333333333334\n","      Recall: 0.9523809523809523\n","      F1-score: 0.888888888888889\n","\n","--- Fold 6 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.8362068965517241\n","    Precision: 0.8312231247013856\n","    Recall: 0.8321759259259259\n","    F1-Score: 0.8298926767676768\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.8461538461538461\n","      Recall: 0.873015873015873\n","      F1-score: 0.859375\n","    Class Malignant:\n","      Precision: 0.8214285714285714\n","      Recall: 0.71875\n","      F1-score: 0.7666666666666666\n","    Class Normal:\n","      Precision: 0.8260869565217391\n","      Recall: 0.9047619047619048\n","      F1-score: 0.8636363636363636\n","\n","--- Fold 7 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.896551724137931\n","    Precision: 0.9090495796877681\n","    Recall: 0.8845899470899471\n","    F1-Score: 0.8956601974594777\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.8805970149253731\n","      Recall: 0.9365079365079365\n","      F1-score: 0.9076923076923077\n","    Class Malignant:\n","      Precision: 0.896551724137931\n","      Recall: 0.8125\n","      F1-score: 0.8524590163934426\n","    Class Normal:\n","      Precision: 0.95\n","      Recall: 0.9047619047619048\n","      F1-score: 0.9268292682926829\n","\n","--- Fold 8 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.853448275862069\n","    Precision: 0.8906406406406407\n","    Recall: 0.816468253968254\n","    F1-Score: 0.8444738554227605\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.8108108108108109\n","      Recall: 0.9523809523809523\n","      F1-score: 0.8759124087591241\n","    Class Malignant:\n","      Precision: 0.9166666666666666\n","      Recall: 0.6875\n","      F1-score: 0.7857142857142857\n","    Class Normal:\n","      Precision: 0.9444444444444444\n","      Recall: 0.8095238095238095\n","      F1-score: 0.8717948717948718\n","\n","--- Fold 9 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.8620689655172413\n","    Precision: 0.8512544802867383\n","    Recall: 0.868882275132275\n","    F1-Score: 0.8584468339307049\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.8870967741935484\n","      Recall: 0.873015873015873\n","      F1-score: 0.88\n","    Class Malignant:\n","      Precision: 0.8333333333333334\n","      Recall: 0.78125\n","      F1-score: 0.8064516129032259\n","    Class Normal:\n","      Precision: 0.8333333333333334\n","      Recall: 0.9523809523809523\n","      F1-score: 0.888888888888889\n","\n","--- Fold 10 ---\n","  Overall Metrics for this Fold:\n","    Accuracy: 0.8362068965517241\n","    Precision: 0.8286351329829591\n","    Recall: 0.8267195767195767\n","    F1-Score: 0.8258522727272727\n","  Per-Class Metrics for this Fold:\n","    Class Benign:\n","      Precision: 0.8461538461538461\n","      Recall: 0.873015873015873\n","      F1-score: 0.859375\n","    Class Malignant:\n","      Precision: 0.8571428571428571\n","      Recall: 0.75\n","      F1-score: 0.7999999999999999\n","    Class Normal:\n","      Precision: 0.782608695652174\n","      Recall: 0.8571428571428571\n","      F1-score: 0.8181818181818182\n","\n","--- Mean Overall Metrics Across All Folds (evaluated on Test_dataset) ---\n","  Mean Accuracy: 0.8474137931034482\n","  Mean Precision: 0.8493385192930472\n","  Mean Recall: 0.8362599206349206\n","  Mean F1-Score: 0.8393009509709746\n","\n","--- Standard Deviation Overall Metrics Across All Folds (evaluated on Test_dataset) ---\n","  Std Dev Accuracy: 0.02041848152125347\n","  Std Dev Precision: 0.030635408479779025\n","  Std Dev Recall: 0.027512258684165746\n","  Std Dev F1-Score: 0.023946335804681994\n","\n","--- Mean Per-Class Metrics Across All Folds (evaluated on Test_dataset) ---\n","  Class Benign:\n","    Mean Precision: 0.8576449248083537\n","    Mean Recall: 0.8904761904761905\n","    Mean F1-score: 0.8724891874019918\n","  Class Malignant:\n","    Mean Precision: 0.8370722827619378\n","    Mean Recall: 0.746875\n","    Mean F1-score: 0.7866719551057177\n","  Class Normal:\n","    Mean Precision: 0.8532983503088497\n","    Mean Recall: 0.8714285714285716\n","    Mean F1-score: 0.8587417104052143\n","\n","--- Standard Deviation Per-Class Metrics Across All Folds (evaluated on Test_dataset) ---\n","  Class Benign:\n","    Std Dev Precision: 0.03517818130792266\n","    Std Dev Recall: 0.03852273364924317\n","    Std Dev F1-score: 0.016426660227128246\n","  Class Malignant:\n","    Std Dev Precision: 0.06513429921113012\n","    Std Dev Recall: 0.04296164714021101\n","    Std Dev F1-score: 0.028556621430074747\n","  Class Normal:\n","    Std Dev Precision: 0.060166328238628226\n","    Std Dev Recall: 0.07079080355865953\n","    Std Dev F1-score: 0.0377595488916165\n"]}],"source":["# Print the evaluation results\n","print(\"Metrics per Fold (evaluated on Test_dataset):\")\n","for fold_num, fold_data in enumerate(metrics_k['fold_metrics']):\n","    print(f\"\\n--- Fold {fold_num + 1} ---\")\n","    print(\"  Overall Metrics for this Fold:\")\n","    for metric_name, value in fold_data['overall'].items():\n","        print(f\"    {metric_name.replace('_', ' ').title()}: {value}\")\n","\n","    print(\"  Per-Class Metrics for this Fold:\")\n","    for class_name, metrics in fold_data['per_class'].items():\n","        print(f\"    Class {class_name}:\")\n","        print(f\"      Precision: {metrics['precision']}\")\n","        print(f\"      Recall: {metrics['recall']}\")\n","        print(f\"      F1-score: {metrics['f1-score']}\")\n","\n","\n","print(\"\\n--- Mean Overall Metrics Across All Folds (evaluated on Test_dataset) ---\")\n","for metric_name, value in metrics_k['mean_overall_metrics'].items():\n","     print(f\"  Mean {metric_name.replace('_', ' ').title()}: {value}\")\n","\n","print(\"\\n--- Standard Deviation Overall Metrics Across All Folds (evaluated on Test_dataset) ---\")\n","for metric_name, value in metrics_k['std_overall_metrics'].items():\n","     print(f\"  Std Dev {metric_name.replace('_', ' ').title()}: {value}\")\n","\n","print(\"\\n--- Mean Per-Class Metrics Across All Folds (evaluated on Test_dataset) ---\")\n","for class_name, metrics in metrics_k['mean_per_class_metrics'].items():\n","    print(f\"  Class {class_name}:\")\n","    print(f\"    Mean Precision: {metrics['precision']}\")\n","    print(f\"    Mean Recall: {metrics['recall']}\")\n","    print(f\"    Mean F1-score: {metrics['f1-score']}\")\n","\n","print(\"\\n--- Standard Deviation Per-Class Metrics Across All Folds (evaluated on Test_dataset) ---\")\n","for class_name, metrics in metrics_k['std_per_class_metrics'].items():\n","    print(f\"  Class {class_name}:\")\n","    print(f\"    Std Dev Precision: {metrics['precision']}\")\n","    print(f\"    Std Dev Recall: {metrics['recall']}\")\n","    print(f\"    Std Dev F1-score: {metrics['f1-score']}\")"]},{"cell_type":"code","execution_count":null,"id":"45fb8cb7-7564-4b5d-8957-6ab698a13183","metadata":{"id":"45fb8cb7-7564-4b5d-8957-6ab698a13183"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}